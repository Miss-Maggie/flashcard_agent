# FlashCard Agent - Deployment & Architecture Guide

## Environment Variables Setup

### Frontend (.env in root directory)

```env
# Supabase Configuration
VITE_SUPABASE_URL=https://mbuvarwoistyjnafjdoo.supabase.co
VITE_SUPABASE_PUBLISHABLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im1idXZhcndvaXN0eWpuYWZqZG9vIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjM2MzY2MTcsImV4cCI6MjA3OTIxMjYxN30.X_4e2B08GdX10UHfoG7CIMU35IOmIQiFE1FNxIoZ_y0
VITE_SUPABASE_PROJECT_ID=mbuvarwoistyjnafjdoo
```

### Backend (supabase/.env for local edge function development)

```env
# Supabase Internal
SUPABASE_URL=https://mbuvarwoistyjnafjdoo.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im1idXZhcndvaXN0eWpuYWZqZG9vIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjM2MzY2MTcsImV4cCI6MjA3OTIxMjYxN30.X_4e2B08GdX10UHfoG7CIMU35IOmIQiFE1FNxIoZ_y0
SUPABASE_PUBLISHABLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im1idXZhcndvaXN0eWpuYWZqZG9vIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjM2MzY2MTcsImV4cCI6MjA3OTIxMjYxN30.X_4e2B08GdX10UHfoG7CIMU35IOmIQiFE1FNxIoZ_y0
SUPABASE_SERVICE_ROLE_KEY=<Get from Lovable Cloud Settings → Advanced → Service Role Key>
SUPABASE_DB_URL=<Get from Lovable Cloud Settings → Advanced → Database URL>

# Google Cloud Vertex AI (Required for flashcard/quiz generation)
GOOGLE_CLOUD_PROJECT_ID=<Your GCP Project ID>
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_SERVICE_ACCOUNT_JSON=<Your full service account JSON as a single-line string>

# Lovable AI (Optional - if using Lovable AI gateway)
LOVABLE_API_KEY=<Auto-generated by Lovable, get from Lovable Cloud Settings>
```

---

## Architecture: Vertex AI + ADK + Genkit Patterns

Your application uses a **hybrid architecture** combining three powerful AI patterns:

### 1. **Vertex AI Integration** (Direct API)

You're making direct API calls to Google Cloud's Vertex AI using the `gemini-2.5-flash` model.

**Key Components:**
- **Authentication**: OAuth2 JWT token exchange using service account credentials
- **Model**: `gemini-2.5-flash` (fast, cost-effective, balanced reasoning)
- **Endpoint**: `https://{location}-aiplatform.googleapis.com/v1/projects/{projectId}/locations/{location}/publishers/google/models/gemini-2.5-flash:generateContent`

**Flow:**
1. Parse service account JSON from environment
2. Create JWT with RS256 signature using private key
3. Exchange JWT for OAuth2 access token
4. Call Vertex AI endpoint with Bearer token

**Location in Code:**
- `supabase/functions/generate-flashcards/index.ts` (lines 55-150)
- `supabase/functions/generate-quiz/index.ts` (lines 64-158)

---

### 2. **ADK (AI Development Kit) Patterns**

ADK patterns provide **structured configuration, validation, and parsing** for AI workflows.

#### Pattern 1: Configuration & Validation
```typescript
const getVertexAIConfig = () => {
  const projectId = Deno.env.get("GOOGLE_CLOUD_PROJECT_ID");
  const location = Deno.env.get("GOOGLE_CLOUD_LOCATION");
  const serviceAccountJson = Deno.env.get("GOOGLE_SERVICE_ACCOUNT_JSON");
  
  if (!projectId || !location || !serviceAccountJson) {
    throw new Error("Vertex AI configuration missing");
  }
  
  return { projectId, location, serviceAccountJson };
};
```

**Purpose**: Ensures all required environment variables are present before making AI calls.

#### Pattern 2: Prompt Template Management
```typescript
const createFlashcardPrompt = (topic: string, mode: string) => {
  const systemContext = mode === "stem"
    ? "You are an expert educator creating challenging STEM flashcards..."
    : "You are an expert educator creating engaging general knowledge flashcards...";
    
  const userPrompt = `Create 6 flashcards about "${topic}"...`;
  
  return { systemContext, userPrompt };
};
```

**Purpose**: Separates prompt logic from API calls, making prompts reusable and testable.

#### Pattern 3: Response Validation & Parsing
```typescript
const parseFlashcards = (content: string) => {
  // Clean markdown code blocks
  let cleanContent = content.trim();
  if (cleanContent.startsWith("```json")) cleanContent = cleanContent.slice(7);
  if (cleanContent.startsWith("```")) cleanContent = cleanContent.slice(3);
  if (cleanContent.endsWith("```")) cleanContent = cleanContent.slice(0, -3);
  
  // Parse and validate
  const flashcards = JSON.parse(cleanContent);
  
  // Validate structure
  flashcards.forEach((fc, index) => {
    if (!fc.question || !fc.answer || !fc.category) {
      throw new Error(`Flashcard ${index} has invalid structure`);
    }
  });
  
  return flashcards;
};
```

**Purpose**: Validates AI responses match expected schema, preventing downstream errors.

---

### 3. **Genkit-Inspired Patterns**

Genkit patterns provide **flow orchestration, logging, and error handling**.

#### Pattern 1: Model Invocation (Structured Output)
```typescript
const callVertexAI = async (prompt: string, systemContext: string, config: any) => {
  // Authentication flow
  const accessToken = await getAccessToken(config);
  
  // Call AI model
  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessToken}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      contents: [
        { role: "user", parts: [{ text: systemContext }, { text: prompt }] }
      ],
      generationConfig: {
        temperature: 0.9,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 2048,
      },
    }),
  });
  
  return await response.json();
};
```

**Purpose**: Encapsulates model communication with consistent error handling and configuration.

#### Pattern 2: Flow Management & Logging
```typescript
Deno.serve(async (req) => {
  try {
    const { topic, mode } = await req.json();
    console.log("[Genkit Flow] Starting flashcard generation for topic:", topic);
    
    // ADK: Get configuration
    const config = getVertexAIConfig();
    console.log("[ADK] Configuration validated");
    
    // ADK: Create prompt from template
    const { systemContext, userPrompt } = createFlashcardPrompt(topic, mode);
    console.log("[ADK] Prompt template created");
    
    // Genkit: Invoke model
    console.log("[Genkit] Invoking Vertex AI model...");
    const aiResponse = await callVertexAI(userPrompt, systemContext, config);
    console.log("[Genkit] Model response received");
    
    // ADK: Parse and validate response
    console.log("[ADK] Parsing and validating flashcards...");
    const flashcards = parseFlashcards(content);
    console.log(`[ADK] Successfully generated ${flashcards.length} flashcards`);
    
    return new Response(JSON.stringify({ flashcards }), { 
      status: 200, 
      headers: { ...corsHeaders, "Content-Type": "application/json" } 
    });
  } catch (error) {
    console.error("[Error]", error.message);
    return new Response(JSON.stringify({ error: "Failed to generate" }), { 
      status: 500 
    });
  }
});
```

**Purpose**: Provides end-to-end logging for debugging and observability.

---

## Error Handling & Reliability

### 1. **JSON Repair Mechanism**

Your system includes automatic JSON repair for truncated responses:

```typescript
if (errorMessage.includes("Unterminated string") || 
    errorMessage.includes("Unexpected end of JSON input") ||
    errorMessage.includes("Unexpected token")) {
  console.log("[Parse Error] Attempting to repair malformed JSON...");
  
  // Find the last complete object
  const lastCompleteObjectMatch = cleanContent.lastIndexOf('}');
  if (lastCompleteObjectMatch !== -1) {
    // Trim to the last complete object and close the array
    const repairedContent = cleanContent.substring(0, lastCompleteObjectMatch + 1) + ']';
    const repairedQuestions = JSON.parse(repairedContent);
    
    // Validate repaired data
    if (Array.isArray(repairedQuestions) && repairedQuestions.length > 0) {
      console.log("[Parse Error] Successfully repaired JSON, recovered", repairedQuestions.length, "questions");
      return repairedQuestions;
    }
  }
}
```

**Why This Matters:**
- AI models occasionally return truncated responses due to token limits or network issues
- Instead of failing completely, the system recovers partial valid data
- Users get 3-4 flashcards instead of 0, improving UX

### 2. **Safety Filter Handling**

```typescript
const finishReason = aiResponse.candidates?.[0]?.finishReason;
if (finishReason === "SAFETY") {
  console.error("[Safety Filter] Content was blocked by safety filters");
  return new Response(
    JSON.stringify({ 
      error: "Content blocked by safety filters. Try a different topic." 
    }),
    { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
  );
}
```

**Why This Matters:**
- Vertex AI blocks potentially harmful content
- System provides clear error messages instead of generic failures

### 3. **Comprehensive Logging**

Every step logs its progress:
- `[Genkit Flow]` - High-level flow events
- `[ADK]` - Configuration, prompt creation, parsing
- `[Genkit]` - Model invocation
- `[Parse Error]` - JSON parsing issues
- `[Error]` - Final error messages

**Benefits:**
- Easy debugging via Supabase Edge Function logs
- Clear audit trail of what went wrong and where

---

## How to Get Service Account JSON

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Select your project
3. Navigate to **IAM & Admin → Service Accounts**
4. Create a new service account or select existing
5. Grant it **Vertex AI User** role
6. Click **Keys → Add Key → Create New Key → JSON**
7. Download the JSON file
8. **Convert to single-line string**: Remove all newlines and spaces
   ```bash
   cat service-account.json | jq -c . | pbcopy
   ```
9. Paste into `GOOGLE_SERVICE_ACCOUNT_JSON` environment variable

---

## Testing Locally

### 1. Install Supabase CLI
```bash
npm install -g supabase
```

### 2. Start Local Supabase
```bash
supabase start
```

### 3. Set Environment Variables
Create `supabase/.env.local` with all secrets above.

### 4. Run Edge Function Locally
```bash
supabase functions serve generate-flashcards --env-file supabase/.env.local
```

### 5. Test with cURL
```bash
curl -X POST http://localhost:54321/functions/v1/generate-flashcards \
  -H "Content-Type: application/json" \
  -d '{"topic": "Photosynthesis", "mode": "stem"}'
```

---

## Deployment Checklist

- [ ] All environment variables configured in Lovable Cloud Settings → Secrets
- [ ] Service account has **Vertex AI User** role
- [ ] `GOOGLE_SERVICE_ACCOUNT_JSON` is single-line escaped JSON
- [ ] Edge functions deployed (automatic in Lovable)
- [ ] Test flashcard generation with a sample topic
- [ ] Test quiz generation with a sample topic
- [ ] Check Supabase Edge Function logs for any errors

---

## Common Issues & Solutions

### Issue: "Vertex AI configuration missing"
**Solution**: Ensure all three secrets are configured:
- `GOOGLE_CLOUD_PROJECT_ID`
- `GOOGLE_CLOUD_LOCATION`
- `GOOGLE_SERVICE_ACCOUNT_JSON`

### Issue: "Token exchange failed: 400"
**Solution**: Your service account JSON is malformed. Re-download and ensure it's properly escaped.

### Issue: "Vertex AI request failed: 403"
**Solution**: Service account lacks permissions. Add **Vertex AI User** role in IAM.

### Issue: "JSON parsing failed: Unterminated string"
**Solution**: This is now automatically repaired. If it persists, the AI response is severely truncated. Check logs for `[Parse Error]` messages.

### Issue: "Content blocked by safety filters"
**Solution**: The topic triggered Vertex AI's safety filters. Try a different topic or rephrase.

---

## Architecture Diagram

```
┌─────────────────────────────────────────────────────────────────┐
│                         Frontend (React)                         │
│  ┌────────────────┐         ┌────────────────┐                 │
│  │ TopicInput.tsx │────────▶│ FlashcardGrid  │                 │
│  └────────────────┘         └────────────────┘                 │
└──────────────────────┬──────────────────────────────────────────┘
                       │
                       │ HTTP POST
                       │
┌──────────────────────▼──────────────────────────────────────────┐
│              Supabase Edge Functions (Deno)                      │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │ generate-flashcards/index.ts                             │  │
│  │                                                           │  │
│  │  1. [ADK] getVertexAIConfig()                            │  │
│  │  2. [ADK] createFlashcardPrompt(topic, mode)             │  │
│  │  3. [Genkit] callVertexAI(prompt, systemContext, config) │  │
│  │  4. [ADK] parseFlashcards(content)                       │  │
│  └─────────────────────────────────────────────────────────┘  │
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │ generate-quiz/index.ts                                   │  │
│  │                                                           │  │
│  │  1. [ADK] getVertexAIConfig()                            │  │
│  │  2. [ADK] createQuizPrompt(topic, mode, flashcards)      │  │
│  │  3. [Genkit] callVertexAI(prompt, systemContext, config) │  │
│  │  4. [ADK] parseQuizQuestions(content)                    │  │
│  └─────────────────────────────────────────────────────────┘  │
└──────────────────────┬──────────────────────────────────────────┘
                       │
                       │ OAuth2 JWT + API Call
                       │
┌──────────────────────▼──────────────────────────────────────────┐
│              Google Cloud Vertex AI                              │
│                                                                  │
│  Model: gemini-2.5-flash                                        │
│  Endpoint: us-central1-aiplatform.googleapis.com                │
│                                                                  │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  1. Receive JWT from service account                    │   │
│  │  2. Validate JWT signature                              │   │
│  │  3. Exchange for access token                           │   │
│  │  4. Process AI generation request                       │   │
│  │  5. Return structured JSON response                     │   │
│  └────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

---

## Why This Architecture?

### ✅ **Pros**
1. **No vendor lock-in**: Direct Vertex AI calls, no third-party wrappers
2. **Cost-effective**: `gemini-2.5-flash` is fast and cheap
3. **Reliable**: Built-in JSON repair and safety filter handling
4. **Observable**: Comprehensive logging at every step
5. **Scalable**: Serverless edge functions auto-scale with traffic

### ⚠️ **Cons**
1. **Manual OAuth2 flow**: More complex than using SDKs
2. **Service account setup**: Requires GCP configuration
3. **JSON parsing fragility**: AI responses need careful validation

---

## Future Improvements

1. **Add Retry Logic**: Automatically retry failed AI calls (3 attempts with exponential backoff)
2. **Implement Caching**: Cache flashcards for popular topics using Supabase tables
3. **Add Rate Limiting**: Prevent abuse with per-user rate limits
4. **Streaming Responses**: Stream flashcards as they're generated for better UX
5. **Fallback Models**: Use `gemini-2.5-flash-lite` if `gemini-2.5-flash` fails

---

## Support

- **Vertex AI Docs**: https://cloud.google.com/vertex-ai/docs
- **Supabase Edge Functions**: https://supabase.com/docs/guides/functions
- **Lovable Cloud Docs**: https://docs.lovable.dev/features/cloud

For issues, check Supabase Edge Function logs in Lovable Cloud → Backend → Functions → Logs.
